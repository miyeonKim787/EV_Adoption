{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLMIZ6NRgF3PcKbx7H0Sla",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miyeonKim787/EV_Adoption/blob/main/Text_Analysis_EV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction**\n",
        "\n",
        "The automotive landscape is undergoing a revolutionary transformation as society pivots towards sustainable and eco-friendly transportation solutions. In August 2022, Congress approved a sweeping reform of the electrical vehicles (\"EV\") tax credits as part of the $430 billion Inflation Reduction Act (IRA).\n",
        "\n",
        "Consumers currently can take advantage of the $7,500 new EV credit or $4,000 used EV credit when they file their tax returns the following year, but starting in January 2024, consumers can transfer the credits to a car dealer, effectively lowering the vehicleâ€™s purchase price.\n",
        "\n",
        "But despite the benefits EVs offer - from government incenvites to contributing to a cleaner form of mobility - the widespread adoption of EVs has been met with various challenges, leading to a slower-than-expected transition from traditional internal combustion engine vehicles (ICE). For example, as reported by The Economist, \"a poll published in July by the Pew Research Centre found that less than two-fifths of them would consider buying an electric vehicle.\"\n",
        "\n",
        "This project attempts to understand the roadblocks to EV adoption, told from the perspective of potential customers, by collecting data via Youtube API and conducting TF-IDF and topic modelling analysis."
      ],
      "metadata": {
        "id": "VQTolZzgU4Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 1 - Data Collection\n",
        "import pandas as pd\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "# YouTube API credentials\n",
        "api_key = 'AIzaSyDVzhKboeANlUp9j63Ga-SRg5fI7Tc2-jc'\n",
        "\n",
        "# Construct YouTube client\n",
        "youtube = build('youtube', 'v3', developerKey=api_key)\n",
        "\n",
        "# Get video ID from URL\n",
        "url = \"https://www.youtube.com/watch?v=cZlsZwcIgpc\"\n",
        "video_id = url.split('=')[1]\n",
        "\n",
        "# Initialize empty list and dataframe\n",
        "comments = []\n",
        "df = pd.DataFrame(columns=['date', 'author', 'comment'])\n",
        "\n",
        "# Build initial API request object\n",
        "request = youtube.commentThreads().list(\n",
        "    part='snippet',\n",
        "    videoId=video_id,\n",
        "    maxResults = 100\n",
        ")\n",
        "\n",
        "# Iterate through API response to retrieve comments\n",
        "while request:\n",
        "\n",
        "    response = request.execute()\n",
        "\n",
        "    for item in response['items']:\n",
        "\n",
        "        # Extract comment data\n",
        "        comment_id = item['id']\n",
        "        date = item['snippet']['topLevelComment']['snippet']['publishedAt']\n",
        "        author = item['snippet']['topLevelComment']['snippet']['authorDisplayName']\n",
        "        text = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
        "\n",
        "        # Construct comment dict\n",
        "        comment = {'date': date,\n",
        "                   'author': author, 'comment': text}\n",
        "\n",
        "        # Append comment to list\n",
        "        comments.append(comment)\n",
        "\n",
        "    # Get next page token\n",
        "    request = youtube.commentThreads().list_next(request, response)\n",
        "\n",
        "# Convert final list of comments to a DataFrame\n",
        "df = pd.DataFrame(comments)\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "offKCfOJ-UOU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53b55cd0-61ce-46a6-ea50-7fb1710e36aa"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       date                 author  \\\n",
            "0      2023-12-17T13:47:04Z             @SickPrid3   \n",
            "1      2023-12-17T08:50:58Z  @racheljustrachel2732   \n",
            "2      2023-12-17T07:01:08Z        @Scorcher-ii1ty   \n",
            "3      2023-12-17T06:57:02Z        @Scorcher-ii1ty   \n",
            "4      2023-12-17T01:19:07Z          @AbronHawkins   \n",
            "...                     ...                    ...   \n",
            "13599  2023-10-16T16:28:51Z          @slash2freeze   \n",
            "13600  2023-10-16T16:28:48Z         @kingayman5225   \n",
            "13601  2023-10-16T16:28:42Z               @JogBird   \n",
            "13602  2023-10-16T16:27:46Z           @kineticstar   \n",
            "13603  2023-10-16T16:27:14Z              @Waltaere   \n",
            "\n",
            "                                                 comment  \n",
            "0      If technology does not sell itself, it;s doome...  \n",
            "1      People should have a choice. With prices have ...  \n",
            "2      Once Trump gets in itâ€™s bye bye EV mandates. Y...  \n",
            "3      I love how Ford calls an EV a Mustang. Where i...  \n",
            "4      Letâ€™s say that working class people canâ€™t affo...  \n",
            "...                                                  ...  \n",
            "13599  I think itâ€™s because of the price is too high....  \n",
            "13600                                     RIP Tesla hype  \n",
            "13601  just in time for Chevy to release its $80k ($9...  \n",
            "13602  The biggest issue is inflation, along with a h...  \n",
            "13603                                             CNBC ðŸ˜ƒ  \n",
            "\n",
            "[13604 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 2 - Data Cleaning\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Lowercase\n",
        "df['comment'] = df['comment'].apply(lambda x: x.lower())\n",
        "\n",
        "# Remove Punctuations\n",
        "df['comment'] = df['comment'].apply(lambda x: re.sub(r'[^\\w\\s]','',x))\n",
        "\n",
        "# Remove Stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "df['comment'] = df['comment'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
        "\n",
        "# Lemmatization\n",
        "from textblob import Word\n",
        "\n",
        "df['comment'] = df['comment'].apply(lambda x: ' '.join([Word(word).lemmatize() for word in x.split()]))\n",
        "\n",
        "# Store cleaned comments\n",
        "cleaned_comments = df['comment']\n",
        "\n",
        "# Print for checking\n",
        "print(cleaned_comments.head(5))"
      ],
      "metadata": {
        "id": "Pl1M10AdE6gp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31c7109e-7454-461d-a37d-8a38a3385e9a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    technology sell doomed failbrevs scam quotgree...\n",
            "1    people choice price gone salary dont go manufa...\n",
            "2    trump get bye bye ev mandate wait 6 hour piece...\n",
            "3    love ford call ev mustang coyote motor garbage...\n",
            "4    let say working class people cant afford espec...\n",
            "Name: comment, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 3 - Topic Modelling\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df['cleaned_comments'])\n",
        "\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "# Tokenize each comment\n",
        "df['tokens'] = df['cleaned_comments'].apply(simple_preprocess)\n",
        "\n",
        "# Create dictionary from tokens\n",
        "dictionary = corpora.Dictionary(df['tokens'])\n",
        "corpus = [dictionary.doc2bow(c) for c in df['tokens']]\n",
        "\n",
        "num_topics = 5\n",
        "ldamodel = gensim.models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary)\n",
        "\n",
        "for topic_id, topic in ldamodel.print_topics(-1):\n",
        "   print(f'Topic {topic_id}: {topic}')\n",
        "\n",
        "# Create corpus based on tokenized texts\n",
        "corpus = [dictionary.doc2bow(text) for text in df['tokens']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqnp-m3bD7nB",
        "outputId": "1873ad3b-3f87-40ab-9fb1-9723894e4086"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: 0.036*\"ev\" + 0.015*\"charging\" + 0.014*\"charge\" + 0.013*\"gas\" + 0.012*\"battery\" + 0.009*\"car\" + 0.009*\"time\" + 0.009*\"cost\" + 0.009*\"tesla\" + 0.008*\"year\"\n",
            "Topic 1: 0.037*\"tesla\" + 0.033*\"ev\" + 0.027*\"car\" + 0.014*\"price\" + 0.013*\"dealer\" + 0.012*\"one\" + 0.012*\"dealership\" + 0.009*\"sale\" + 0.009*\"model\" + 0.009*\"buy\"\n",
            "Topic 2: 0.017*\"car\" + 0.017*\"ev\" + 0.014*\"battery\" + 0.010*\"vehicle\" + 0.009*\"electric\" + 0.009*\"power\" + 0.007*\"time\" + 0.007*\"fire\" + 0.007*\"go\" + 0.006*\"fuel\"\n",
            "Topic 3: 0.036*\"ev\" + 0.019*\"car\" + 0.018*\"charging\" + 0.013*\"vehicle\" + 0.013*\"battery\" + 0.012*\"people\" + 0.009*\"cost\" + 0.009*\"range\" + 0.009*\"infrastructure\" + 0.008*\"electric\"\n",
            "Topic 4: 0.048*\"ev\" + 0.016*\"want\" + 0.016*\"people\" + 0.012*\"car\" + 0.011*\"government\" + 0.011*\"don\" + 0.010*\"get\" + 0.007*\"buy\" + 0.007*\"ice\" + 0.006*\"going\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 4 - TF-IDF Analysis\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Dataframe from extracted and cleaned comments\n",
        "df = pd.DataFrame({'cleaned_comments': cleaned_comments})\n",
        "\n",
        "# Create vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Generate vectors\n",
        "tfidf_vectors = vectorizer.fit_transform(df['cleaned_comments'])\n",
        "\n",
        "# Get feature names (terms/tokens)\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "\n",
        "# Print vector for first comment document\n",
        "print(tfidf_vectors[0])\n",
        "\n",
        "# Get vector densities across corpus\n",
        "print(tfidf_vectors.shape)\n",
        "\n",
        "# Print term frequencies for first term\n",
        "print(tfidf_vectors[:,0].toarray()[0])\n",
        "\n",
        "# Print few sample terms\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "first_vector = tfidf_vectors[0]\n",
        "\n",
        "for idx in first_vector.indices:\n",
        "   print(feature_names[idx])"
      ],
      "metadata": {
        "id": "kZhD_PNaNTXI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "798e3a31-68cc-48f3-940a-b2f10bc4e8db"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 4593)\t0.12582249574342833\n",
            "  (0, 20731)\t0.18535554527984333\n",
            "  (0, 18198)\t0.23516849611041138\n",
            "  (0, 19450)\t0.25534587466924025\n",
            "  (0, 10674)\t0.2447379595752156\n",
            "  (0, 1646)\t0.2455273040899731\n",
            "  (0, 12871)\t0.27259947576643784\n",
            "  (0, 21280)\t0.3097283705460124\n",
            "  (0, 13797)\t0.21852458012636952\n",
            "  (0, 5511)\t0.25816575426747207\n",
            "  (0, 10492)\t0.12653280097592276\n",
            "  (0, 15744)\t0.3457278498973869\n",
            "  (0, 17223)\t0.18223947205491653\n",
            "  (0, 8129)\t0.36060967845441944\n",
            "  (0, 6712)\t0.27259947576643784\n",
            "  (0, 17396)\t0.1552663975842386\n",
            "  (0, 19058)\t0.16514927191895404\n",
            "(13604, 21531)\n",
            "[0.]\n",
            "charge\n",
            "waiting\n",
            "spent\n",
            "time\n",
            "important\n",
            "accident\n",
            "minor\n",
            "written\n",
            "often\n",
            "cost\n",
            "ice\n",
            "quotgreenerquot\n",
            "scam\n",
            "failbrevs\n",
            "doomed\n",
            "sell\n",
            "technology\n"
          ]
        }
      ]
    }
  ]
}